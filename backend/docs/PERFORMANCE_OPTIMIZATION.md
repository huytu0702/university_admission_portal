# Performance Optimization cho Design Patterns

## Hiá»‡n tráº¡ng

Benchmark cho tháº¥y patterns cÃ³ overhead:
- Latency: +18.56% (258ms â†’ 306ms)
- Throughput: -15.90% (193 â†’ 162 req/s)

**ÄÃ¢y lÃ  trade-off há»£p lÃ½** giá»¯a performance vÃ  reliability.

---

## Optimization Strategies

### 1. Database Optimization â­â­â­

#### a) Add Indexes
```sql
-- Idempotency checks
CREATE INDEX idx_idempotency_key ON idempotency_store(idempotency_key);
CREATE INDEX idx_idempotency_expires ON idempotency_store(expires_at) WHERE processed = true;

-- Outbox relay
CREATE INDEX idx_outbox_unprocessed ON outbox(created_at) WHERE processed = false;

-- CQRS Read Model
CREATE INDEX idx_app_view_user ON application_view(user_id, created_at DESC);
```

#### b) Connection Pooling
```typescript
// prisma/schema.prisma
datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
  // TÄƒng connection pool
  connection_limit = 50  // tá»« 10 lÃªn 50
}
```

**Expected improvement**: -20ms latency

---

### 2. Redis Optimization â­â­â­

#### a) Connection Pooling
```typescript
// Trong queue config
const redisConfig = {
  maxRetriesPerRequest: 3,
  enableReadyCheck: false,
  // Lazy connect
  lazyConnect: true,
  // Connection pool
  maxConnections: 10,
};
```

#### b) Pipeline Commands
```typescript
// Thay vÃ¬ nhiá»u commands riÃªng láº»
await redis.set(key1, val1);
await redis.set(key2, val2);

// DÃ¹ng pipeline
const pipeline = redis.pipeline();
pipeline.set(key1, val1);
pipeline.set(key2, val2);
await pipeline.exec();
```

**Expected improvement**: -10ms latency

---

### 3. Async Processing â­â­â­

Hiá»‡n táº¡i code **chá»** queue job Ä‘Æ°á»£c enqueue:
```typescript
// âŒ Synchronous - chá» queue
await this.queueProducerService.addVerifyDocumentJob(...);
```

Äá»•i thÃ nh fire-and-forget:
```typescript
// âœ… Async - khÃ´ng chá»
this.queueProducerService.addVerifyDocumentJob(...).catch(err => 
  this.logger.error('Queue enqueue failed', err)
);
```

**Expected improvement**: -30ms latency

---

### 4. Optimize Outbox Pattern â­â­

#### a) Batch Inserts
Thay vÃ¬ insert tá»«ng outbox event:
```typescript
// Batch create outbox events
await tx.outbox.createMany({
  data: [
    { eventType: 'document_uploaded', payload: '...' },
    { eventType: 'application_submitted', payload: '...' },
  ]
});
```

#### b) Async Outbox Relay
TÄƒng táº§n suáº¥t relay tá»« má»—i 5s â†’ má»—i 1s:
```typescript
// outbox-relay.service.ts
@Cron('*/1 * * * * *')  // Tá»« */5 â†’ */1
async processOutbox() { ... }
```

**Expected improvement**: -15ms latency

---

### 5. Cache Idempotency Checks â­â­

ThÃªm Redis cache cho idempotency:
```typescript
async executeWithIdempotency(key: string, fn: Function) {
  // 1. Check Redis cache first
  const cached = await this.redis.get(`idem:${key}`);
  if (cached) return JSON.parse(cached);
  
  // 2. Check database
  const existing = await this.prisma.idempotencyStore.findUnique(...);
  if (existing) {
    // Cache for 1 hour
    await this.redis.setex(`idem:${key}`, 3600, JSON.stringify(existing.result));
    return existing.result;
  }
  
  // 3. Execute
  const result = await fn();
  await this.redis.setex(`idem:${key}`, 3600, JSON.stringify(result));
  return result;
}
```

**Expected improvement**: -25ms latency

---

### 6. Worker Concurrency â­

TÄƒng sá»‘ workers xá»­ lÃ½ jobs:
```typescript
// worker-scaling.service.ts
private readonly workerPools = {
  verify: { min: 2, max: 10, targetConcurrency: 5 },  // Tá»« 3 lÃªn 5
  payment: { min: 2, max: 8, targetConcurrency: 4 },   // Tá»« 2 lÃªn 4
  email: { min: 1, max: 5, targetConcurrency: 3 },     // Tá»« 2 lÃªn 3
};
```

**Expected improvement**: Tá»‘t hÆ¡n cho sustained load

---

## Priority Implementation

| Priority | Optimization | Effort | Impact |
|----------|-------------|--------|--------|
| ğŸ”¥ P0 | Async Queue Enqueue | Low | -30ms |
| ğŸ”¥ P0 | Database Indexes | Low | -20ms |
| â­ P1 | Redis Connection Pool | Medium | -10ms |
| â­ P1 | Cache Idempotency | Medium | -25ms |
| ğŸ“ P2 | Batch Outbox | Medium | -15ms |
| ğŸ“ P2 | Worker Concurrency | Low | Scalability |

**Tá»•ng expected improvement**: ~100ms latency reduction

---

## Quan trá»ng: Patterns vs Raw Performance

### Khi nÃ o NÃŠN dÃ¹ng patterns?
- Production environment
- CÃ³ traffic spike
- Cáº§n reliability cao (financial, important data)
- Multi-service architecture

### Khi nÃ o CÃ“ THá»‚ táº¯t má»™t sá»‘ patterns?
- Development/testing
- Low traffic
- Non-critical features (analytics, logging)

### Benchmark Ä‘Ãºng cÃ¡ch
Thay vÃ¬ so sÃ¡nh "ALL ON" vs "ALL OFF", nÃªn test vá»›i **real load**:
```powershell
# Test vá»›i spike traffic
npm run benchmark:full -- -c 100  # 100 concurrent connections

# Monitor error rate, not just latency
```

Patterns sáº½ shine khi cÃ³:
- Concurrent requests cao
- Database contention
- External service failures
